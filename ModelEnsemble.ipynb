{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results from logistic regression, random forest, xgboost, and support vector machine models as well as the actual outcomes\n",
    "lr_train = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Train_Results_LR.csv\")\n",
    "rf_train = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Train_Results_RF.csv\")\n",
    "xgb_train = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Train_Results_XGB.csv\")\n",
    "svm_train = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Train_Results_SVM.csv\")\n",
    "train = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/insurance_t_var_sel.csv\")\n",
    "\n",
    "lr_val = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Val_Results_LR.csv\")\n",
    "rf_val = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Val_Results_RF.csv\")\n",
    "xgb_val = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Val_Results_XGB.csv\")\n",
    "svm_val = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/Val_Results_SVM.csv\")\n",
    "val = pd.read_csv(\"/Users/jinwoolee/Downloads/Bank Project/insurance_v_var_sel.csv\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "lr_train = lr_train.iloc[:,1:]\n",
    "rf_train = rf_train.iloc[:,1:]\n",
    "xgb_train = xgb_train.iloc[:,1:]\n",
    "svm_train = svm_train.iloc[:,1:]\n",
    "\n",
    "lr_val = lr_val.iloc[:,1:]\n",
    "rf_val = rf_val.iloc[:,1:]\n",
    "xgb_val = xgb_val.iloc[:,1:]\n",
    "svm_val = svm_val.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all column names are unique\n",
    "lr_train = lr_train.add_prefix('lr_')\n",
    "rf_train = rf_train.add_prefix('rf_')\n",
    "xgb_train = xgb_train.add_prefix('xgb_')\n",
    "svm_train = svm_train.add_prefix('svm_')\n",
    "\n",
    "lr_val = lr_val.add_prefix('lr_')\n",
    "rf_val = rf_val.add_prefix('rf_')\n",
    "xgb_val = xgb_val.add_prefix('xgb_')\n",
    "svm_val = svm_val.add_prefix('svm_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_INS_hat</th>\n",
       "      <th>rf_INS_hat</th>\n",
       "      <th>xgb_INS_hat</th>\n",
       "      <th>svm_INS_hat</th>\n",
       "      <th>INS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266802</td>\n",
       "      <td>0.169618</td>\n",
       "      <td>0.270573</td>\n",
       "      <td>0.252406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.548340</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.293375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193319</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>0.211512</td>\n",
       "      <td>0.224764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056678</td>\n",
       "      <td>0.051203</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>0.163091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133114</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.066098</td>\n",
       "      <td>0.342586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8490</th>\n",
       "      <td>0.293323</td>\n",
       "      <td>0.156632</td>\n",
       "      <td>0.220222</td>\n",
       "      <td>0.264814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>0.159250</td>\n",
       "      <td>0.161872</td>\n",
       "      <td>0.232675</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.615451</td>\n",
       "      <td>0.663242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8493</th>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.547997</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.282478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8494</th>\n",
       "      <td>0.845626</td>\n",
       "      <td>0.295036</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.745892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8495 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_INS_hat  rf_INS_hat  xgb_INS_hat  svm_INS_hat  INS\n",
       "0       0.266802    0.169618     0.270573     0.252406    0\n",
       "1       0.383170    0.548340     0.380722     0.293375    1\n",
       "2       0.193319    0.487821     0.211512     0.224764    1\n",
       "3       0.056678    0.051203     0.040926     0.163091    0\n",
       "4       0.133114    0.090675     0.066098     0.342586    0\n",
       "...          ...         ...          ...          ...  ...\n",
       "8490    0.293323    0.156632     0.220222     0.264814    0\n",
       "8491    0.159250    0.161872     0.232675     0.221875    0\n",
       "8492    0.685649    0.300947     0.615451     0.663242    0\n",
       "8493    0.383170    0.547997     0.380722     0.282478    1\n",
       "8494    0.845626    0.295036     0.694268     0.745892    0\n",
       "\n",
       "[8495 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_INS_hat</th>\n",
       "      <th>rf_INS_hat</th>\n",
       "      <th>xgb_INS_hat</th>\n",
       "      <th>svm_INS_hat</th>\n",
       "      <th>INS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593103</td>\n",
       "      <td>0.582504</td>\n",
       "      <td>0.699762</td>\n",
       "      <td>0.579246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600585</td>\n",
       "      <td>0.692401</td>\n",
       "      <td>0.584207</td>\n",
       "      <td>0.843043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247363</td>\n",
       "      <td>0.154176</td>\n",
       "      <td>0.183272</td>\n",
       "      <td>0.308266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340257</td>\n",
       "      <td>0.430390</td>\n",
       "      <td>0.620933</td>\n",
       "      <td>0.271137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.335489</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.320905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.410554</td>\n",
       "      <td>0.486962</td>\n",
       "      <td>0.407026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>0.836258</td>\n",
       "      <td>0.685989</td>\n",
       "      <td>0.712844</td>\n",
       "      <td>0.997192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.492979</td>\n",
       "      <td>0.460989</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.515796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.498604</td>\n",
       "      <td>0.587774</td>\n",
       "      <td>0.589570</td>\n",
       "      <td>0.371313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.215042</td>\n",
       "      <td>0.410870</td>\n",
       "      <td>0.361115</td>\n",
       "      <td>0.289612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2124 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_INS_hat  rf_INS_hat  xgb_INS_hat  svm_INS_hat  INS\n",
       "0       0.593103    0.582504     0.699762     0.579246    1\n",
       "1       0.600585    0.692401     0.584207     0.843043    1\n",
       "2       0.247363    0.154176     0.183272     0.308266    0\n",
       "3       0.340257    0.430390     0.620933     0.271137    0\n",
       "4       0.409441    0.335489     0.380722     0.320905    0\n",
       "...          ...         ...          ...          ...  ...\n",
       "2119    0.313131    0.410554     0.486962     0.407026    1\n",
       "2120    0.836258    0.685989     0.712844     0.997192    1\n",
       "2121    0.492979    0.460989     0.626987     0.515796    1\n",
       "2122    0.498604    0.587774     0.589570     0.371313    1\n",
       "2123    0.215042    0.410870     0.361115     0.289612    0\n",
       "\n",
       "[2124 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all training results to one data frame\n",
    "train_results = lr_train.join([rf_train, xgb_train, svm_train, train['INS']])\n",
    "\n",
    "# Combine all validation results to one data frame\n",
    "val_results = lr_val.join([rf_val, xgb_val, svm_val, val['INS']])\n",
    "\n",
    "display(train_results)\n",
    "display(val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emsembling Techniques for Binary Classification\n",
    "\n",
    "* **Simple Average**: Take the average across all predicted probabilities\n",
    "* **Weighted Average**: Take the average across all predicted probabilities with more (or less) weights given to certain models\n",
    "* **Rank Average**: Rank all predicted probabilities by columns and then take the average \n",
    "* **Weighted Rank Average**: Rank all predicted probabilities by columns and then take the average with more (or less) weights given to certain models\n",
    "\n",
    "* **NOTE**: If all our models were made with scikit-learn, then we could use VotingClassifier to get a majority vote or soft vote (weighted average predicted probabilities) to predict the class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_INS_hat</th>\n",
       "      <th>rf_INS_hat</th>\n",
       "      <th>xgb_INS_hat</th>\n",
       "      <th>svm_INS_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266802</td>\n",
       "      <td>0.169618</td>\n",
       "      <td>0.270573</td>\n",
       "      <td>0.252406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.548340</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.293375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193319</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>0.211512</td>\n",
       "      <td>0.224764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056678</td>\n",
       "      <td>0.051203</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>0.163091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133114</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.066098</td>\n",
       "      <td>0.342586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8490</th>\n",
       "      <td>0.293323</td>\n",
       "      <td>0.156632</td>\n",
       "      <td>0.220222</td>\n",
       "      <td>0.264814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>0.159250</td>\n",
       "      <td>0.161872</td>\n",
       "      <td>0.232675</td>\n",
       "      <td>0.221875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.615451</td>\n",
       "      <td>0.663242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8493</th>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.547997</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.282478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8494</th>\n",
       "      <td>0.845626</td>\n",
       "      <td>0.295036</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.745892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8495 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_INS_hat  rf_INS_hat  xgb_INS_hat  svm_INS_hat\n",
       "0       0.266802    0.169618     0.270573     0.252406\n",
       "1       0.383170    0.548340     0.380722     0.293375\n",
       "2       0.193319    0.487821     0.211512     0.224764\n",
       "3       0.056678    0.051203     0.040926     0.163091\n",
       "4       0.133114    0.090675     0.066098     0.342586\n",
       "...          ...         ...          ...          ...\n",
       "8490    0.293323    0.156632     0.220222     0.264814\n",
       "8491    0.159250    0.161872     0.232675     0.221875\n",
       "8492    0.685649    0.300947     0.615451     0.663242\n",
       "8493    0.383170    0.547997     0.380722     0.282478\n",
       "8494    0.845626    0.295036     0.694268     0.745892\n",
       "\n",
       "[8495 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset the predicted probability columns\n",
    "probs = train_results.iloc[:,0:4]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr has an AUC of 0.8021492795178671\n",
      "rf has an AUC of 0.9916156057085039\n",
      "xgb has an AUC of 0.8442189741156367\n",
      "svm has an AUC of 0.7796560041775416\n"
     ]
    }
   ],
   "source": [
    "# Print the AUC of each of the models\n",
    "for col in probs:\n",
    "    auc = roc_auc_score(train_results['INS'], probs[col])\n",
    "    print(f\"{col.split('_')[0]} has an AUC of {auc}\")\n",
    "\n",
    "# Goal: Get an AUC better than the highest AUC printed with the exception of the random forest model's AUC as it is unreasonably high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051925912789518"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Average\n",
    "simple_avg = np.mean(probs, axis = 1)\n",
    "roc_auc_score(train_results['INS'], simple_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 0.1, 0.1)\n",
      "0.9486796046083229\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average\n",
    "weighted_avg = (probs['lr_INS_hat'] + probs['rf_INS_hat'] + probs['xgb_INS_hat'] + probs['svm_INS_hat']) / 4\n",
    "auc = roc_auc_score(train_results['INS'], weighted_avg)\n",
    "\n",
    "# Define best coeffecient combination and range of values for i, j, k, and l\n",
    "best_coef = None\n",
    "values_range = np.linspace(0.1, 5, 15)  # 15 values from 0 to 5\n",
    "\n",
    "# Perform search\n",
    "for i in values_range:\n",
    "    for j in values_range:\n",
    "        for k in values_range:\n",
    "            # Because the random forest AUC is high, its weight will be 0.25\n",
    "            weighted_avg_temp = (i*probs['lr_INS_hat'] + 0.25*probs['rf_INS_hat'] + j*probs['xgb_INS_hat'] + k*probs['svm_INS_hat']) / (i+j+k+0.25)\n",
    "            if roc_auc_score(train_results['INS'], weighted_avg_temp) > auc:\n",
    "                weighted_avg = weighted_avg_temp\n",
    "                auc = roc_auc_score(train_results['INS'], weighted_avg_temp)\n",
    "                best_coef = (i, j, k)\n",
    "\n",
    "print(best_coef)\n",
    "print(auc)\n",
    "\n",
    "# For the weight of the random forest model, have tried 1, 0.5, and 0.25\n",
    "# With all of them, we get (i, j, k) = (0.1, 0.1, 0.1), but since the AUC is still high when weight = 1 or 0.5, we move forward with weight = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8767255310198316"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank Average\n",
    "rank_avg = np.mean(probs.rank(), axis = 1)\n",
    "roc_auc_score(train_results['INS'], rank_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 0.1, 0.1)\n",
      "0.9167872601204178\n"
     ]
    }
   ],
   "source": [
    "# Rank Weighted Average\n",
    "rank_weighted_avg = (probs['lr_INS_hat'].rank() + probs['rf_INS_hat'].rank() + probs['xgb_INS_hat'].rank() + probs['svm_INS_hat'].rank()) / 4\n",
    "rank_auc = roc_auc_score(train_results['INS'], rank_weighted_avg)\n",
    "\n",
    "# Define best coeffecient combination and range of values for i, j, k, and l\n",
    "rank_best_coef = None\n",
    "values_range = np.linspace(0.1, 5, 15)  # 15 values from 0 to 5\n",
    "\n",
    "# Perform search\n",
    "for i in values_range:\n",
    "    for j in values_range:\n",
    "        for k in values_range:\n",
    "            # Because the random forest AUC is high, its weight will be 0.25\n",
    "            rank_weighted_avg_temp = (i*probs['lr_INS_hat'].rank() + 0.25*probs['rf_INS_hat'].rank() + j*probs['xgb_INS_hat'].rank() + k*probs['svm_INS_hat'].rank()) / (i+j+k+0.25)\n",
    "            if roc_auc_score(train_results['INS'], rank_weighted_avg_temp) > rank_auc:\n",
    "                rank_weighted_avg = rank_weighted_avg_temp\n",
    "                rank_auc = roc_auc_score(train_results['INS'], rank_weighted_avg_temp)\n",
    "                rank_best_coef = (i, j, k)\n",
    "\n",
    "print(rank_best_coef)\n",
    "print(rank_auc)\n",
    "\n",
    "# For the weight of the random forest model, have tried 1, 0.5, and 0.25\n",
    "# With all of them, we get (i, j, k) = (0.1, 0.1, 0.1), but since the AUC is still high when weight = 1 or 0.5, we move forward with weight = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Given that the weighted average yields the highest AUC, we would move forward with this ensembling technique. However, for exploration purposes, let's see how the other emsembles perform on the validation dataset. First, we visualize the ROC curve using the weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Cut-off</th>\n",
       "      <th>Youden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.846813</td>\n",
       "      <td>0.112785</td>\n",
       "      <td>0.384743</td>\n",
       "      <td>0.734028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.847156</td>\n",
       "      <td>0.113143</td>\n",
       "      <td>0.384563</td>\n",
       "      <td>0.734012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.872858</td>\n",
       "      <td>0.138964</td>\n",
       "      <td>0.357589</td>\n",
       "      <td>0.733895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.871830</td>\n",
       "      <td>0.138067</td>\n",
       "      <td>0.358679</td>\n",
       "      <td>0.733763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>0.849554</td>\n",
       "      <td>0.115833</td>\n",
       "      <td>0.381910</td>\n",
       "      <td>0.733722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR       FPR   Cut-off    Youden\n",
       "704  0.846813  0.112785  0.384743  0.734028\n",
       "706  0.847156  0.113143  0.384563  0.734012\n",
       "808  0.872858  0.138964  0.357589  0.733895\n",
       "806  0.871830  0.138067  0.358679  0.733763\n",
       "714  0.849554  0.115833  0.381910  0.733722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cutoff is 0.38\n",
      "Youden's Index (K-S Statistic) is 0.73\n",
      "Model's AUC is 0.95\n"
     ]
    }
   ],
   "source": [
    "# Visualize the ROC curve\n",
    "\n",
    "# Establish the false positive rate, true positive rate, and the optimal cutoff\n",
    "fpr, tpr, thresholds = roc_curve(train_results['INS'], (0.1*probs['lr_INS_hat'] + 0.25*probs['rf_INS_hat'] + 0.1*probs['xgb_INS_hat'] + 0.1*probs['svm_INS_hat']) / (0.1+0.25+0.1+0.1))\n",
    "\n",
    "# Compute Youden's Index\n",
    "data = {'TPR': tpr, 'FPR': fpr, 'Cut-off': thresholds, 'Youden': tpr-fpr}\n",
    "youden = pd.DataFrame(data)\n",
    "youden = youden.sort_values(by = ['Youden'], ascending = False)\n",
    "display(youden.head(5))\n",
    "\n",
    "# Plot ROC curve\n",
    "roc_display = RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = auc(fpr, tpr))\n",
    "roc_display.plot()\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('1-Specificity (FPR)')\n",
    "plt.ylabel('Sensitivity (TPR)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the optimal cutoff, Youden's index, and AUC\n",
    "print(\"Optimal cutoff is\", round(youden.loc[704, 'Cut-off'], 2))\n",
    "print(\"Youden's Index (K-S Statistic) is\", round(youden.loc[704, 'Youden'], 2))\n",
    "print(\"Model's AUC is\", str(round(auc(fpr, tpr), 2)))\n",
    "\n",
    "# With an AUC of 0.95, it still seems to be potentially overfitting the training dataset even though we greatly reduced the weight of the random forest model\n",
    "# Will still need to see how it performs on the validation dataset to be certain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_INS_hat</th>\n",
       "      <th>rf_INS_hat</th>\n",
       "      <th>xgb_INS_hat</th>\n",
       "      <th>svm_INS_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593103</td>\n",
       "      <td>0.582504</td>\n",
       "      <td>0.699762</td>\n",
       "      <td>0.579246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600585</td>\n",
       "      <td>0.692401</td>\n",
       "      <td>0.584207</td>\n",
       "      <td>0.843043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247363</td>\n",
       "      <td>0.154176</td>\n",
       "      <td>0.183272</td>\n",
       "      <td>0.308266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340257</td>\n",
       "      <td>0.430390</td>\n",
       "      <td>0.620933</td>\n",
       "      <td>0.271137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.335489</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.320905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.410554</td>\n",
       "      <td>0.486962</td>\n",
       "      <td>0.407026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>0.836258</td>\n",
       "      <td>0.685989</td>\n",
       "      <td>0.712844</td>\n",
       "      <td>0.997192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.492979</td>\n",
       "      <td>0.460989</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.515796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.498604</td>\n",
       "      <td>0.587774</td>\n",
       "      <td>0.589570</td>\n",
       "      <td>0.371313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.215042</td>\n",
       "      <td>0.410870</td>\n",
       "      <td>0.361115</td>\n",
       "      <td>0.289612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_INS_hat  rf_INS_hat  xgb_INS_hat  svm_INS_hat\n",
       "0       0.593103    0.582504     0.699762     0.579246\n",
       "1       0.600585    0.692401     0.584207     0.843043\n",
       "2       0.247363    0.154176     0.183272     0.308266\n",
       "3       0.340257    0.430390     0.620933     0.271137\n",
       "4       0.409441    0.335489     0.380722     0.320905\n",
       "...          ...         ...          ...          ...\n",
       "2119    0.313131    0.410554     0.486962     0.407026\n",
       "2120    0.836258    0.685989     0.712844     0.997192\n",
       "2121    0.492979    0.460989     0.626987     0.515796\n",
       "2122    0.498604    0.587774     0.589570     0.371313\n",
       "2123    0.215042    0.410870     0.361115     0.289612\n",
       "\n",
       "[2124 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset the predicted probability columns\n",
    "probs_val = val_results.iloc[:,0:4]\n",
    "probs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988208034763478\n",
      "0.7991601686684012\n",
      "0.7994566256177811\n",
      "0.8000183335218696\n"
     ]
    }
   ],
   "source": [
    "# Simple Average\n",
    "print(roc_auc_score(val_results['INS'], np.mean(probs_val, axis = 1)))\n",
    "\n",
    "# Weighted Average\n",
    "print(roc_auc_score(val_results['INS'], (0.1*probs_val['lr_INS_hat'] + 0.25*probs_val['rf_INS_hat'] + 0.1*probs_val['xgb_INS_hat'] + 0.1*probs_val['svm_INS_hat']) / (0.1+0.25+0.1+0.1)))\n",
    "\n",
    "# Rank Average\n",
    "print(roc_auc_score(val_results['INS'], np.mean(probs_val.rank(), axis = 1)))\n",
    "\n",
    "# Rank Weighted Average\n",
    "print(roc_auc_score(val_results['INS'], (0.1*probs_val['lr_INS_hat'].rank() + 0.25*probs_val['rf_INS_hat'].rank() + 0.1*probs_val['xgb_INS_hat'].rank() + 0.1*probs_val['svm_INS_hat'].rank()) / (0.1+0.25+0.1+0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's AUC is 0.8\n"
     ]
    }
   ],
   "source": [
    "# Visualize the ROC curve\n",
    "\n",
    "# Establish the false positive rate, true positive rate, and the optimal cutoff\n",
    "fpr, tpr, thresholds = roc_curve(val_results['INS'], (0.1*probs_val['lr_INS_hat'] + 0.25*probs_val['rf_INS_hat'] + 0.1*probs_val['xgb_INS_hat'] + 0.1*probs_val['svm_INS_hat']) / (0.1+0.25+0.1+0.1))\n",
    "\n",
    "# Plot ROC curve\n",
    "roc_display = RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = auc(fpr, tpr))\n",
    "roc_display.plot()\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('1-Specificity (FPR)')\n",
    "plt.ylabel('Sensitivity (TPR)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the AUC\n",
    "print(\"Model's AUC is\", str(round(auc(fpr, tpr), 2)))\n",
    "\n",
    "# This ensemble is the best model so far with an AUC of 0.8 on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INS_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "INS_pred     0    1\n",
       "INS                \n",
       "0         1003  379\n",
       "1          195  547"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix where we make predictions from predicted probabilities based on the optimal cut-off\n",
    "val['INS_pred'] = ((0.1*probs_val['lr_INS_hat'] + 0.25*probs_val['rf_INS_hat'] + 0.1*probs_val['xgb_INS_hat'] + 0.1*probs_val['svm_INS_hat']) / (0.1+0.25+0.1+0.1)).map(lambda x: 1 if x > (youden.loc[704, 'Cut-off']) else 0)\n",
    "pd.crosstab(val['INS'], val['INS_pred'])\n",
    "\n",
    "# Overall, in terms of being able to discriminate between customers who buy or do not buy the annuity product,\n",
    "# the weighted average ensemble performs better compared to any individual model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
